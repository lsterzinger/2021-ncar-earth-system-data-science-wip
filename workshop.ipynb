{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# NCAR Earth System Data Science WIP Talk\n",
    "### Lucas Sterzinger -- Atmospheric Science PhD Candidate at UC Davis\n",
    "* [Twitter](https://twitter.com/lucassterzinger)\n",
    "* [GitHub](https://github.com/lsterzinger)\n",
    "* [Website](https://lucassterzinger.com)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  Motivation:\n",
    "* NetCDF is not cloud optimized\n",
    "* Other formats, like Zarr, aim to "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# What do I mean when I say \"Cloud Optimized\"?\n",
    "![Move to cloud diagram](images/cloud-move.png)\n",
    "\n",
    "In traditional scientific workflows, data is archived in a repository and downloaded to a separate computer for analysis (left). However, datasets are becoming much too large to fit on personal computers, and transferring full datasets from an archive to a seperate machine can use lots of bandwidth.\n",
    "\n",
    "In a cloud environment, the data can live in object storage (e.g. AWS S3), and analysis can be done in an adjacent compute instances, allowing for low-latency and high-bandwith access to the dataset.\n",
    "\n",
    "## Why NetCDF doesn't work well in this workflow\n",
    "\n",
    "NetCDF is probably the most common binary data format for atmospheric/earth sciences, and has a lot of official and community support. However, the NetCDF format requires either a) loading the entire dataset in order to access the header/metadata and retreive a chunk of data.\n",
    "\n",
    "![NetCDF File Object](images/single_file_object.png)\n",
    "\n",
    "## The Zarr Solution\n",
    "The [Zarr data format](https://zarr.readthedocs.io/en/stable/) alleviates this problem by storing the metadata and chunks in seperate files that can be accessed as-needed and in parallel.\n",
    "\n",
    "![Zarr](images/zarr.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import `fsspec-reference-maker` and make sure it's at the latest version (`0.0.3` at the time of writing)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import fsspec_reference_maker\n",
    "fsspec_reference_maker.__version__"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from fsspec_reference_maker.hdf import SingleHdf5ToZarr\n",
    "from fsspec_reference_maker.combine import MultiZarrToZarr\n",
    "import fsspec"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup an S3 filesystem for listing GOES files on S3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fs = fsspec.filesystem('s3', anon=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "flist = fs.glob(\"s3://noaa-goes16/ABI-L2-SSTF/2020/210/*/*.nc\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepend `s3://` to the URLS"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "flist = ['s3://' + f for f in flist]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Start a dask cluster"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "client"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import dask.bag as db\n",
    "flist_bag = db.from_sequence(flist)\n",
    "flist_bag"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Definte function to return a reference dictionary for a given S3 file URL"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def gen_ref(f):\n",
    "    so = dict(\n",
    "        mode=\"rb\", anon=True, default_fill_cache=False, default_cache_type=\"none\"\n",
    "    )\n",
    "\n",
    "    with fsspec.open(f, **so) as infile:\n",
    "        return SingleHdf5ToZarr(infile, f, inline_threshold=300).translate()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Map `gen_ref` to each member of `flist_bag` and compute"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dicts = flist_bag.map(gen_ref).compute()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use `MultiZarrToZarr` to combine the 24 individual references into a single reference"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mzz = MultiZarrToZarr(\n",
    "    dicts,\n",
    "    remote_protocol='s3',\n",
    "    remote_options={'anon':True},\n",
    "    xarray_open_kwargs={\n",
    "        \"decode_cf\" : False,\n",
    "        \"mask_and_scale\" : False,\n",
    "        \"decode_times\" : False,\n",
    "        \"decode_timedelta\" : False,\n",
    "        \"use_cftime\" : False,\n",
    "        \"decode_coords\" : False\n",
    "    },\n",
    "    xarray_concat_args={'dim' : 't'}\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "References can be saved to a file (`combined.json`) or passed back as a dictionary (`mzz_dict`)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mzz.translate('combined.json')\n",
    "# mzz_dict = mzz.translate()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read the referenced files with `fsspec` and `xarray`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fs2 = fsspec.filesystem('reference', fo=\"./combined.json\", remote_protocol='s3', remote_options=dict(anon=True), skip_instance_cache=True)\n",
    "ds = xr.open_dataset(fs2.get_mapper(\"\"), engine='zarr')\n",
    "ds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import metpy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ds1 = ds.metpy.parse_cf()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import hvplot.xarray"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ds_latlon = ds1.metpy.assign_latitude_longitude()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ds_latlon"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ds.metpy.assign_latitude_longitude"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mask_lat"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mask_lat = (ds_latlon.latitude > 0) & (ds_latlon.latitude < 50)\n",
    "mask_lon = (ds_latlon.longitude >-90) & (ds_latlon.latitude < -60)\n",
    "\n",
    "ds3 = ds.where((ds_latlon.latitude > 0) & (ds_latlon.latitude < 50) & (ds_latlon.longitude >-90) & (ds_latlon.latitude < -60))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ds3 = ds3.metpy.parse_cf()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ds3.SST.isel(t=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ds3.SST.isel(t=0).hvplot.quadmesh()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d70f57c3b6c84dbefd961a001699fac508781729051fe0260f54471ebbaeb3c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}